---
title: Hearing Colour
date: "2021-11-20"
thumbnail: ./hearingcolour.png
figcaption: The hearing colour app with the colour picker on the left and the collaborative visualisation in the background. 
description: This web app allowed the audience of an experimental music concert to create a collaborative visualisation with their phones during the performance. It was first presented at Iklectic in London in November 2021. 
---

This project is part of my ongoing collaboration with <a rel="noopener noreferrer" target="_blank" href="http://eecs.qmul.ac.uk/profiles/saitischaralampos.html">Charalampos Saitis</a> at the Centre for Digital Music.
As researchers we are interested in the associations that people have between the visual and the auditory world, but rather than only conducting lab studies we try to gain new insights from the "real-world".

Concert-goers can load a web app on their phones and pick a colour that will then appear as a moving blob on a large screen on the stage. 
It creates an intruiging, interactive experience for the audience while also generating research data.

`youtube:https://www.youtube.com/watch?v=qS6Ze8n4j8A`

The app was presented to about 100 visitors at the <a rel="noopener noreferrer" target="_blank" href="https://iklectikartlab.com/hearing-colour-sonic-worlds-and-other-senses/">Iklectik</a> venue in London for a performance by <a rel="noopener noreferrer" target="_blank" href="https://xeniapestovabennett.com/">Xenia Pestova Bennett</a>
in collaboration with <a rel="noopener noreferrer" target="_blank" href="http://andrewmcpherson.org/">Andrew McPherson</a> of the Augmented Instruments Lab.

I used React.js, p5.js and WebGL for development. The code is available on <a rel="noopener noreferrer" target="_blank" href="https://github.com/SFRL/hearing-colour-app">GitHub</a>. This project was a great excercise in developing an app in a couple of days that works smoothly and intuitively for a larger number of simoultaneous users.

